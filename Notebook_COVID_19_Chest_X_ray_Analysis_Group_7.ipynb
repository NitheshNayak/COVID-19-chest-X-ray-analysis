{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook_COVID_19_Chest_X_ray_Analysis_Group_7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitheshNayak/COVID-19-chest-X-ray-analysis/blob/main/Notebook_COVID_19_Chest_X_ray_Analysis_Group_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1XvjMu7wpa0"
      },
      "source": [
        "## COVID-19 Chest X-ray Analysis\n",
        "    By, \n",
        "        Tamara Orth\n",
        "        Joshua Baudin \n",
        "        Nithesh Nayak "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lakXaNjNw0il"
      },
      "source": [
        "# # connect to local working directory on Google Colab - This cell block has to be commented if not using google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5Bmsny8xBsE"
      },
      "source": [
        "# add my working directory to the Notebook path\n",
        "import sys\n",
        "WORKSPACE = \"/content/drive/My Drive/MyFiles/IFN646/COVID-19 Radiography Database/\" # download kaggle dataset and use the folder path - https://www.kaggle.com/tawsifurrahman/covid19-radiography-database\n",
        "sys.path.append(WORKSPACE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD6tkE-zwpa2"
      },
      "source": [
        "#Importing Libraries\n",
        "import os\n",
        "\n",
        "import cv2 #Importing openCV-2\n",
        "\n",
        "#Basic Python Libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "#Visualization Libraries \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#sklearn \n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "#Keras\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#TensorFlow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import  VGG19\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, MaxPooling2D, GlobalAveragePooling2D, Dropout, BatchNormalization, Conv2D, InputLayer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTkT4gCYwpa7"
      },
      "source": [
        "# Obtain list of image paths. Last line is to verify number of image paths obtained matches number of expected images for our dataset.\n",
        "\n",
        "filePaths = []\n",
        "#Fetching filenames from the data directory\n",
        "for directory, _, ImageFilenames in os.walk(WORKSPACE):\n",
        "    for ImageName in ImageFilenames:\n",
        "        if (ImageName[-3:] == 'png'):\n",
        "            filePaths.append(os.path.join(directory, ImageName))\n",
        "\n",
        "#Check whether all the images are imported from actual \n",
        "if len(filePaths) == 219+1341+1345:\n",
        "    print(\"All Files are imported\")\n",
        "else:\n",
        "    print(\"Error ! Some Files are missing !!!\")\n",
        "print(len(filePaths))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fT-7A-kwwpbB"
      },
      "source": [
        "# View a sample image in the dataSet\n",
        "def SampleImage (fileName):\n",
        "    print(filePaths[fileName])\n",
        "    imageSample = cv2.imread(filePaths[fileName])\n",
        "    print(imageSample.shape)\n",
        "    plt.imshow(imageSample)\n",
        "    plt.show()\n",
        "\n",
        "SampleImage(455) #Normal\n",
        "SampleImage(55) # COVID-19\n",
        "\n",
        "SampleImage(2555) #Viral Pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d3mJhzuwpbF"
      },
      "source": [
        "# Creating an array containing image label and data from the above created list\n",
        "\n",
        "ImageData = [] ; ImageLabel = []\n",
        "IMG_SIZE = 224 #Image Size\n",
        "\n",
        "print(\"Code block Running ..\")\n",
        "for file_path in filePaths:\n",
        "    label = file_path.split(os.path.sep)[-2]\n",
        "    \n",
        "#     image = cv2.imread(file_path)\n",
        "    image = cv2.cvtColor(cv2.imread(file_path), cv2.COLOR_BGR2RGB)\n",
        "    #Resizing the image to 224 x 224 resolution and the normalizing the image pixel to by diving 255  \n",
        "    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))/255.0 \n",
        "    \n",
        "    ImageData.append(image) #Store resized and Normalised Image into a list \n",
        "    ImageLabel.append(label)\n",
        "\n",
        "X = np.array(ImageData)\n",
        "y = np.array(ImageLabel)\n",
        "print(\"Code block completed ..\")\n",
        "\n",
        "print(\"Shape of the entire image array -\",X.shape)\n",
        "print(\"Size of Label array - \", y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmfyVbNAwpbK"
      },
      "source": [
        "#Summary of all the three class of images\n",
        "yy =y.copy()\n",
        "\n",
        "y_df = pd.DataFrame(y, columns=['Labels'])\n",
        "\n",
        "ClassCount_df=y_df['Labels'].value_counts()\n",
        "\n",
        "ClassCount_df_02=pd.DataFrame(ClassCount_df).reset_index()\n",
        "\n",
        "\n",
        "ClassCount_df_02=ClassCount_df_02.rename(columns={\"index\": \"Class\"})\n",
        "\n",
        "\n",
        "ClassCount_df_02['Class'] = ClassCount_df_02['Class'].str.replace('COVID-19 Radiography Database/', '')\n",
        "\n",
        "print(ClassCount_df_02)\n",
        "\n",
        "# Pie chart distribution all the three classes in the dataset\n",
        "labels = ClassCount_df_02['Class'] ; sizes = ClassCount_df_02['Labels']\n",
        "\n",
        "explode = (0, 0, 0.2)  # Explode only 2nd SLice i.e. COVID-19\n",
        "\n",
        "fig1, ax1 = plt.subplots()\n",
        "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', shadow=True, startangle=90)\n",
        "ax1.axis('equal') \n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoBTnGIpwpbO"
      },
      "source": [
        "# One-Hot encoding for all the three classes \n",
        "\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "#Converting to one hot encoding \n",
        "y_encoded = np_utils.to_categorical(y_encoded)\n",
        "print(\"Total Files converted - \", len(y_encoded))\n",
        "# print(y_encoded, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M5AqfQ_wpbS"
      },
      "source": [
        "#Splitting the data into Train and test using Stratified Sampling since all the class data is not uniformaly distributed\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.30,  random_state=43, stratify=y_encoded)\n",
        "\n",
        "print(\"Number of Training Images and its Dimention  - \", X_train.shape) \n",
        "\n",
        "# (m,nx,ny,nz) where m - Number of samples | nx,ny is the resolution of the image and nz is number of layer of image (i.e. now R,G,B) \n",
        "\n",
        "print(\"Number of Test Images and its Dimention - \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P1XvBQQwpbX"
      },
      "source": [
        "#Data augmentation : To increase the number of images, augmenting the present images to expand the dataset. \n",
        "\n",
        "train_aug = ImageDataGenerator(rotation_range=15)\n",
        "\n",
        "#The lung images are some what symetrical ( since lungs are in symetry) so rather than flipping a symettric image we have tilted the image\n",
        "# We have obserevd in other dataset the chest X-rays where bit tilted, so as to recrreat similar senario we have tiled the images by 15 degree's\n",
        "#https://keras.io/api/preprocessing/image/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6sX8M0gwpbb"
      },
      "source": [
        "#Transfer learning with VGG19 \n",
        "\n",
        "#Since we have found through our Literature Review that VGG-19 has given promising results in the field of chest x-rays , \n",
        "# we are transfer learning from VGG19 to our sequential model with Fully Connected Layers\n",
        "\n",
        "def Model_VGG19():\n",
        "    # base_model = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "    \n",
        "    base_model = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    base_model.trainable = False # Freeze the the Base model\n",
        "    \n",
        "    #Include_Top - We have not included the fully connected layer at the top \n",
        "    #Weights = We have Used pretrained weights from the famous Imagenet Model here \n",
        "    #Input Shape - Shape of the image was kept same as mentioned in the previous steps\n",
        "    #pooling - We have not included any pooling here - So that no global avergae pooling will be applied to last convolutional block\n",
        "    \n",
        "   \n",
        "    output = base_model.layers[-1].output #Last layer will be our fully connected output layer\n",
        "    \n",
        "    output = Flatten()(output) #Since the ouput is bactch, i.e. without feature axis, Flattening the output layer adds an extra channel dimension \n",
        "    \n",
        "    model = Model(base_model.input, outputs=output) #Model input and pouputs \n",
        "    \n",
        "    ## Freeze all the layers\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S--fjxCfwpbf"
      },
      "source": [
        "# Neural Transfer \n",
        "covid_XR_model = Sequential()\n",
        "\n",
        "covid_XR_model.add(Model_VGG19()) #VGG19 model\n",
        "covid_XR_model.add(Dropout(0.25))\n",
        "\n",
        "#Adding the Dense Layers \n",
        "covid_XR_model.add(Dense(512, activation='relu'))\n",
        "covid_XR_model.add(Dropout(0.25))\n",
        "covid_XR_model.add(Dense(64, activation='relu'))\n",
        "\n",
        "covid_XR_model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "covid_XR_model.summary() #There are 20M non trained parameters, which are from VGG19. Here in the transfer learning we have freezed the VGG19 model (base Model) i.e. layer1.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRKaUw6Iwpbj"
      },
      "source": [
        "# Set constants and hyperparameter values:\n",
        "LR = 0.0001  #Learning Rate\n",
        "EPOCHS = 7\n",
        "BATCH_SIZE = 32 \n",
        "\n",
        "#instantiate the optimizer\n",
        "optim = Adam(lr = LR, decay = LR/EPOCHS)\n",
        "\n",
        "#Configure the model Losses and metrics\n",
        "covid_XR_model.compile(loss='categorical_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
        "\n",
        "#Train the Model \n",
        "history = covid_XR_model.fit(train_aug.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
        "                                    steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "                                    validation_data=(X_test, y_test),\n",
        "                                    validation_steps=len(X_test)//BATCH_SIZE,\n",
        "                                    epochs=EPOCHS,\n",
        "                                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtVceHI5wpbn"
      },
      "source": [
        "#Model Accuracy Graph\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "# Graph Labelling \n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3k5IHcWwpbs"
      },
      "source": [
        "#Model Loss vairation with epoches \n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('Variation in COVID_XR model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0KN_jWiwpbv"
      },
      "source": [
        "# Testing the model \n",
        "TestResult = covid_XR_model.evaluate(X_test, y_test)\n",
        "print(\"Model test accuracy : %f.\" %(TestResult[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLlSZMLXwpby"
      },
      "source": [
        "# Confusion matrix to evaluate the model classification accuracy \n",
        "\n",
        "print(\"Predicting the labels for test data-set ... \")\n",
        "y_pred = np.argmax(covid_XR_model.predict(X_test), axis=1) # Predicting results on test data set\n",
        "\n",
        "print(\"Extracting actual test data-set labels ... \")\n",
        "y_test_labels = np.argmax(y_test, axis=1) # Extracting actual test labels \n",
        "\n",
        "print(\"Confusion Matrix for the model\")\n",
        "EvaluationMatrix = confusion_matrix(y_test_labels, y_pred)\n",
        "EvaluationMatrix_df = pd.DataFrame(EvaluationMatrix, index=le.classes_, columns=le.classes_)\n",
        "EvaluationMatrix_df.columns =['COVID-19', 'NORMAL','Viral Pneumonia'] \n",
        "EvaluationMatrix_df.index =['COVID-19', 'NORMAL','Viral Pneumonia'] \n",
        "\n",
        "print(EvaluationMatrix_df.head())\n",
        "\n",
        "#Creating the Heat Map\n",
        "sns.set(font_scale=1.5, color_codes=True, palette='deep')\n",
        "sns.heatmap(EvaluationMatrix_df, annot=True, annot_kws={'size':16}, fmt='d', cmap='Blues')\n",
        "\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.title('Confusion Matrix of Validation Data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meBjRVVKx4be"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "-----------------"
      ]
    }
  ]
}